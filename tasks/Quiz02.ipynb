{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fb457b21-befc-4e15-a682-f287e481a063",
   "metadata": {},
   "source": [
    "# Quiz 2\n",
    "\n",
    "Topics Included:\n",
    "- Lecture 7\n",
    "- Lecture 8\n",
    "\n",
    "There will two components: \n",
    "- a theoretical part\n",
    "- a coding segment.\n",
    "  \n",
    "You will complete the theoretical part in a Word document, while the coding tasks should be completed using a Python Notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddf5bca7",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58597a44-f440-4082-96db-ba8264439e7d",
   "metadata": {},
   "source": [
    "## <span style=\"color: cyan; font-weight:bold\">OpenCV </span>\n",
    "methods you should know (list is not exhaustive)\n",
    "\n",
    "Image Operations:\n",
    "\n",
    "- <span style=\"color: pink\"><b>cv2.cvtColor </b>(image, colorCode) </span>\n",
    "\n",
    "    <u>Documentation:</u> https://docs.opencv.org/3.4/d8/d01/group__imgproc__color__conversions.html\n",
    "    \n",
    "    <u>Examples:</u> \n",
    "    - image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) -> converts BGR to RGB\n",
    "\n",
    "- <span style=\"color: pink\"><b>cv2.resize </b>(image, shape) </span>\n",
    "\n",
    "    <u>Documentation: </u> https://docs.opencv.org/4.x/da/d6e/tutorial_py_geometric_transformations.html\n",
    "    \n",
    "    <u>Examples:</u>\n",
    "    - Scaling: res = cv.resize(img,None,fx=2, fy=2, interpolation = cv.INTER_CUBIC)\n",
    "    - Changing dimensions: image = cv.resize (image, (original.shape[1], original.shape[0]))\n",
    "- <span style=\"color: pink\"> <b>cv2.flip </b>(image, orientation) </span>\n",
    "\n",
    "    <u>Documentation: </u> https://www.opencvhelp.org/tutorials/image-processing/how-to-flip-image/\n",
    "\n",
    "    <u>Examples:</u>\n",
    "    - Flip horizontally: flipped = cv2.flip(img, 0)\n",
    "    - Flip vertically: flipped = cv2.flip(img, 1)\n",
    "    \n",
    "- <span style=\"color: pink\"><b>cv2.rotate </b>(image, rotateCode) </span>\n",
    "\n",
    "    <u>Examples:</u>\n",
    "    - cv2.rotate(img, rotateCode) -> rotateCode can be:\n",
    "        - cv2.ROTATE_90_CLOCKWISE\n",
    "        - cv2.ROTATE_180\n",
    "        - cv2.ROTATE_90_COUNTERCLOCKWISE\n",
    "\n",
    "Feature Detection and Matching:\n",
    "- <span style=\"color: pink\"><b>cv.SIFT_create()</b></span>\n",
    "- <span style=\"color: pink\"><b>cv.sift.detect </b>(image, None) \n",
    "- <span style=\"color: pink \"><b>cv.sift.compute </b>(image, keypoints) \n",
    "- <span style=\"color: pink\"><b>cv.detectAndCompute </b> (image, None) </span>\n",
    "- <span style=\"color: pink\"><b>cv.BFMatcher </b> ([normType[, crossCheck]]) </span>\n",
    "\n",
    "    <u>Notes:</u>\n",
    "    - normType = specifies the distance measurement (cv2.NORM_L1 for Manhattan and cv2.NORM_l2 for Euclidean (default))\n",
    "    - crossCheck = When set to True, enforces a reciprocal check between the matches. In other words, if the matching algorithm finds a match from the first set of keypoints to the second set, it checks if the match from the second set back to the first set is also the best match. If not, that match is rejected. (Default Value = False)\n",
    "\n",
    "Image Transformations:\n",
    "\n",
    "- <span style=\"color: pink\"><b>cv2.warpPerspective</b> (src, M, dsize) </span>\n",
    "\n",
    "    <u>Documentation:</u> https://docs.opencv.org/4.x/da/d6e/tutorial_py_geometric_transformations.html\n",
    "\n",
    "    <u>Notes:</u>\n",
    "    - Takes a <b>3x3 transformation matrix</b> as an input\n",
    "    - Applies a perspective transformation to an image\n",
    "    - Used to apply a perspective transformation to an <b>image</b>\n",
    "    - Can get the matrix using cv2.getPerspectiveTransform\n",
    "    \n",
    "    <u>Examples:</u>\n",
    "    - dst = cv.warpPerspective(img,M,(300,300))\n",
    "\n",
    "- <span style=\"color: pink \"> <b>cv2.warpAffine </b>(src, M, dsize) </span>\n",
    "\n",
    "    <u>Notes:</u>\n",
    "    - Takes a <b>2x3 transformation matrix</b>\n",
    "    - dsize is (width, height)\n",
    "    - Used to apply an affine transformation to an <b>image</b>\n",
    "\n",
    "\n",
    "- <span style=\"color: pink \"><b>cv2.getPerspectiveTransform </b>(src, dst) </span>\n",
    "\n",
    "    <u>Documentation:</u>\n",
    "\n",
    "    <u>Notes:</u>\n",
    "    - Calculates a perspective transform from four pairs of the corresponding points\n",
    "    - Gives you the 3x3 transformation matrix\n",
    "    - src: a set of 4 points\n",
    "    - dst: a set of 4 corresponding destination points\n",
    "    - Resulting matrix can be used for cv2.perspectiveTransform\n",
    "\n",
    "- <span style=\"color: pink \"><b>cv2.getAffineTransform </b>(src, dst) </span>\n",
    "\n",
    "    <u>Notes:</u>\n",
    "    - Gives you a 2x3 transformation matrix?\n",
    "    - src: a set of 3 points\n",
    "    - dst: a set of 3 corresponding destination points\n",
    "    - Resulting matrix can be used with cv2.warpAffine\n",
    "\n",
    "- <span style=\"color: pink\"><b>cv.findHomography</b> (src, dst, [method, [ransacReprojThreshold]])</span>\n",
    "\n",
    "    <u>Notes:</u>\n",
    "    - src: array of points from the source image (x,y)\n",
    "    - method: method used to compute the homography matrix (cv2.RANSAC)\n",
    "    - ransacReprojThreshold: used with RANSAC to set the max allowed reprojection error to treat a point pair as an inlier (higher value = more relaxed homography)\n",
    "    - Used to find the perspective transformation between two images or sets of points\n",
    "- <span style=\"color: pink; font-weight:bold\">cv.perspectiveTransform</span>\n",
    "\n",
    "    <u>Notes:</u>\n",
    "    - Used to apply a perspective transform to a set of points\n",
    "    - Often used after cv2.findHomography\n",
    "\n",
    "- <span style=\"color: pink; font-weight:bold\">perspectiveTransform</span>\n",
    "\n",
    "Visualzation:\n",
    "- <span style=\"color: pink\"><b>cv.polylines</b> (img, pts, isClosed, color, thickness, lineType)</span>\n",
    "\n",
    "    <u>Notes:</u>\n",
    "    - Draws a polygon on the image corresponding to the transformed points\n",
    "    - pts must be converted to int --> [np.int32(pts)]\n",
    "    - isClosed --> last pt is connected to the first\n",
    "\n",
    "    <u>Examples:</u>\n",
    "    - output_image = cv2.polylines(image2,[np.int32(dst)],True,255,3, cv2.LINE_AA)   \n",
    "\n",
    "\n",
    "- <span style=\"color: pink\"><b>cv.drawKeypoints </b>(img, kp, outImage[, color = [, flags]]) </span>\n",
    "\n",
    "    <u>Notes:</u>\n",
    "    - flags can be cv2.DRAW_MATCHES_FLAGS_DEFAULT or cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS\n",
    "\n",
    "- <span style=\"color: pink \"><b>cv.drawMatches </b>(img1, kp1, img2, kp2, matches1to2, outImg[, matchColor[, singlePointColor[, flags]]]) </span>\n",
    "\n",
    "    <u>Notes:</u>\n",
    "    - flags can be cv2.DRAW_MATCHES_FLAGS_DEFAULT, cv2.DRAW_MATCHES_FLAGS_NOT_DRAW_SINGLE_POINTS, or cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS\n",
    "    - set outImg to None\n",
    "\n",
    "\n",
    "\n",
    "## <span style=\"color: cyan; font-weight:bold\">NumPy</span>\n",
    "NumPy methods that you should be familiar with (list is not exhaustive):\n",
    "\n",
    "Creation of Arrays:\n",
    "\n",
    "- np.array: Create an array from a list or tuple.\n",
    "- np.zeros and numpy.ones: Create arrays filled with zeros or ones.\n",
    "- np.arange: Create an array with regularly spaced values.\n",
    "\n",
    "Array Attributes:\n",
    "\n",
    "- ndarray.shape: Returns the dimensions of the array.\n",
    "- ndarray.dtype: Returns the data type of the array.\n",
    "\n",
    "Indexing and Slicing:\n",
    "\n",
    "- Array indexing and slicing: Access and manipulate elements of arrays.\n",
    "\n",
    "Mathematical Operations:\n",
    "\n",
    "- np.dot: Compute dot product of two arrays.\n",
    "- np.sum, np.mean, np.min, np.max: \n",
    "\n",
    "Array Manipulation:\n",
    "\n",
    "- np.reshape: Reshape an array.\n",
    "- np.concatenate, numpy.vstack, numpy.hstack: Combine arrays.\n",
    "    - np.concatenate((array1, array2), axis)\n",
    "        - axis = 0 -> like vstack (join along the rows)\n",
    "        - axis = 1 -> like hstack (join along the columns)\n",
    "\n",
    "Linear Algebra:\n",
    "\n",
    "- np.linalg.inv: Compute the inverse of a matrix.\n",
    "- np.linalg.det: Compute the determinant of a matrix.\n",
    "- np.linalg.det: Compute the determinant of a matrix.\n",
    "\n",
    "Random:\n",
    "\n",
    "- np.random.rand, numpy.random.randn: Generate random values.\n",
    "- np.random.seed: Set the seed for reproducibility.\n",
    "\n",
    "- np.where: Return elements chosen from two arrays depending on a condition.\n",
    "- np.unique: Find unique elements of an array.\n",
    "\n",
    "\n",
    "## <span style=\"color: cyan; font-weight:bold\">Matplotlib pyplot</span>\n",
    "functions you should know (list is not exhaustive)\n",
    "\n",
    "Basic Plotting:\n",
    "\n",
    "- plt.plot()\n",
    "- plt.scatter()\n",
    "- plt.hist()\n",
    "\n",
    "Axes and Labels:\n",
    "\n",
    "- plt.xlabel(), plt.ylabel() Set the x and y-axis labels.\n",
    "- plt.title(), Set the title of the plot.\n",
    "- plt.legend(), Add a legend to the plot.\n",
    "- plt.grid(), Display grid lines on the plot.\n",
    "\n",
    "Axis Control:\n",
    "\n",
    "- plt.xlim(), plt.ylim(), set the x and y-axis limits.\n",
    "\n",
    "- plt.subplots()\n",
    "\n",
    "- plt.axis([xmin, xmax, ymin, ymax])\n",
    "\n",
    "    - **xmin, xmax, ymin, ymax**: Optional parameters that specify the axis limits.\n",
    "    - **equal**: Maintain aspect ratio, meaning one unit on the x-axis is equal to one unit on the y-axis (Helpful to avoid distortions)\n",
    "\n",
    "Showing:\n",
    "\n",
    "- plt.imshow()\n",
    "- plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32988dc2",
   "metadata": {},
   "source": [
    "# Keypoint/Descriptor Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42362442-ef78-45b2-875e-5c638875a9c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Angle = ', kp[0].angle)              # angle of the point\n",
    "print('Coordinates = ', kp[0].pt)           # coordinates of the keypoint\n",
    "print('Octave = ', kp[0].octave)            # which octave is this point from\n",
    "print('Diameter = ', kp[0].size)            # diameter of the meaningful keypoint neighborhood\n",
    "print('Response = ', kp[0].response)        # response by which the most strong keypoints have been selected\n",
    "print(des[0].shape)                         # shape of the descriptor (dimension of each feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1518ab7e",
   "metadata": {},
   "source": [
    "**Drawing Keypoints**\n",
    "\n",
    "Instead of listing the keypoints manually, we may also plot the keypoints using `cv2.drawKeypoints()`.\n",
    "\n",
    "`cv2.drawKeypoints(image, keypoints, outImage[, color = [, flags]])`\n",
    "\n",
    "- **image**: The original image on which you want to draw the keypoints.\n",
    "- **keypoints**: The list of keypoints for the passed image.\n",
    "- **outImage**: An optional parameter that specifies the output image where the keypoints will be drawn.\n",
    "- **color**: The color of the keypoints. It is specified as a tuple in BGR format.\n",
    "- **flags**: Additional drawing options:\n",
    "    - **cv2.DRAW_MATCHES_FLAGS_DEFAULT**: Default value. Draws keypoints without any additional information.\n",
    "    - **cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS**: Draws keypoints with additional information, such as size and orientation. This can be useful for visualizing more details about each detected keypoint."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac8ec250",
   "metadata": {},
   "source": [
    "# Transformations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4482f1fd",
   "metadata": {},
   "source": [
    "An **affine transformation** is any transformation of the form:\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix} x' \\\\ y' \\\\ 1 \\end{bmatrix} = \\begin{bmatrix} a & b & c \\\\ d & e & f \\\\ 0 & 0 & 1 \\end{bmatrix} \\begin{bmatrix} x \\\\ y \\\\ 1 \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "Thus all the geometric transformations we discussed so far such as translation, rotation, scaling, etc are all affine transformations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa3b4bca",
   "metadata": {},
   "source": [
    "A **perspective transformation** is any transformation of the form:\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix} x' \\\\ y' \\\\ 1 \\end{bmatrix} = \\begin{bmatrix} a & b & c \\\\ d & e & f \\\\ g & h & 1 \\end{bmatrix} \\begin{bmatrix} x \\\\ y \\\\ 1 \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "From the name, the perspective transformation is associated with a change in the viewpoint."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

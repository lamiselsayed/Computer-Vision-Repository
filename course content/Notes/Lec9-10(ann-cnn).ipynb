{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helpful Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color: cyan; font-weight:bold\">Preprocessing </span>\n",
    "- <span style=\"color: pink\"><b>transforms.RandomAffine </b>(degrees, translate=None, scale=None, shear=None, interpolation='nearest', fill=0, fillcolor=None, resample=None) </span>\n",
    "\n",
    "    <u>Documentation</u>:\n",
    "    - https://pytorch.org/vision/0.9/transforms.html \n",
    "\n",
    "    <u>Notes:</u>\n",
    "    - Random affine transformation of the image keeping center invariant\n",
    "    -  If the image is torch Tensor, it is expected to have […, H, W] shape, where … means an arbitrary number of leading dimensions\n",
    "    - degrees is a range of degrees to select from (set as 0 for no rotation)\n",
    "    -  translate is used to translate horizontally and vertically using (a,b)\n",
    "    - scale is the scaling factor (a,b) and the factor is selected within this range\n",
    "    - shear is a range of degrees to choose from or a number\n",
    "    - interpolation is decided using transforms.InterpolationMode (only NEAREST and BILINEAR work with tensors)\n",
    "    - fill is the pixel fill value for the area outside the transformed image\n",
    "\n",
    "\n",
    "- <span style=\"color: pink\"><b>Dataloader </b>(dataset, batch_size, shuffle) </span>\n",
    "\n",
    "    <u>Notes:</u>\n",
    "    - Helps with iterating over a dataset\n",
    "    - Includes batching (essential for large datasets)\n",
    "    - Shuffles the data when set to True so the model doesn't learn the exact order of the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color: cyan; font-weight:bold\">Training </span>\n",
    "- <span style=\"color: pink\"><b>F.one_hot </b>(y) </span>\n",
    "\n",
    "    <u>Notes:</u>\n",
    "    - Used to one hot encode \n",
    "    - Important to use with classification along with softmax/sigmoid \n",
    "    - Each label is represented as a distinct vector where a value of 1 is the label\n",
    "\n",
    "- <span style=\"color: pink\"><b>torch.nn.Linear </b>(in_features, out_features, bias = True) </span>\n",
    "\n",
    "    <u>Notes:</u>\n",
    "    - Creates a Dense layer with linear transformation (fully connected)\n",
    "    - in_features is the size of the input sample\n",
    "    - out_features is the size of the output sample\n",
    "    - bias indicates whether bias should be included for the neurons in this layers\n",
    "\n",
    "- <span style=\"color: pink\"><b>torch.nn.MaxPool2d </b>(kernel_size, stride) </span>\n",
    "\n",
    "    <u>Notes:</u>\n",
    "    - Performs 2D max pooling over the input \n",
    "    - Downsamples the input to reduce its dimensions while maintaining the important points\n",
    "\n",
    "- <span style=\"color: pink\"><b>nn.ReLU </b>() </span>\n",
    "\n",
    "    <u>Notes:</u>\n",
    "    - Applies a rectified linear unit ReLU activation function\n",
    "\n",
    "- <span style=\"color: pink\"><b>torch.nn.Conv2d </b>(in_channels, out_channels, kernel_size, stride, padding) </span>\n",
    "\n",
    "    <u>Notes:</u>\n",
    "    - Creates a convolutional layer\n",
    "    - in and out channels describe the input and output channels dimensions (3 for RGB input)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color: cyan; font-weight:bold\">Performance Metrics </span>\n",
    "- <span style=\"color: pink\"><b>accuracy_score </b>(y_real, y_predicted) </span>\n",
    "- <span style=\"color: pink\"><b>precision_score </b>(y_real, y_predicted, average='macro') </span>\n",
    "- <span style=\"color: pink\"><b>recall_score </b>(y_real, y_predicted, average='macro') </span>\n",
    "- <span style=\"color: pink\"><b>f1_score </b>(y_real, y_predicted, average='macro') </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Needed Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch import optim, nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torchvision import datasets, transforms, models\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "\n",
    "import os\n",
    "import tempfile\n",
    "from PIL import Image\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
    "from ray import tune, train\n",
    "from ray.train import Checkpoint, session\n",
    "from ray.tune.schedulers import ASHAScheduler\n",
    "\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Datasets can be imported from `torchvision` or used through a custom dataset class\n",
    "\n",
    "1. Using `torchvision`\n",
    "    - Import the `datasets` module from `torchvision`\n",
    "    - Define a directory (`data_directory`) where the datasets will be stored\n",
    "    - Import the training dataset (ex:`datasets.MNIST()`) with the following arguments:\n",
    "        - `root`: The directory where the data will be stored\n",
    "        - `train=True`: Indicates that we want to import the training dataset\n",
    "        - `download=True`: Tells PyTorch to download the dataset if it's not already downloaded\n",
    "        - `transform=None`: By default, the transform is set to `None`, which means no transformations will be applied to the data. You can specify transformations here if needed (e.g., resizing, normalization).\n",
    "    - We import the testing dataset in a similar way, but with `train=False` to indicate that we want to import the testing dataset.\n",
    "\n",
    "2. Creating your own custom dataset class\n",
    "    - Based on the structure of your dataset, you need to create a class with specific functions to load the images \n",
    "    - You can then use `random_split` or any similar function to split the dataset into training and testing\n",
    "    - Find below an example used for HW 3 with directories' names as the labels for the images:\n",
    "        - Dimsum\n",
    "        - Cookies\n",
    "        - Sushi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.classes = os.listdir(root_dir)\n",
    "        self.class_to_idx = {cls: idx for idx, cls in enumerate(self.classes)}\n",
    "        self.images = self._load_images()\n",
    "\n",
    "    def _load_images(self):\n",
    "        images = []\n",
    "        for cls in self.classes:\n",
    "            class_dir = os.path.join(self.root_dir, cls)\n",
    "            for img_name in os.listdir(class_dir):\n",
    "                img_path = os.path.join(class_dir, img_name)\n",
    "                images.append((img_path, self.class_to_idx[cls]))\n",
    "        return images\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path, label = self.images[idx]\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result size of the convolution is determined by the formula:\n",
    "\n",
    "$$\\text{{Result size}} = \\frac{{W - F + 2P}}{S} + 1$$\n",
    "\n",
    "where\n",
    "\n",
    "- $W$: Input size\n",
    "- $F$: Filter size\n",
    "- $P$: Padding\n",
    "- $S$: Stride"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ray Tune"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Steps:\n",
    "- Modify the class to include the chosen parameters to be tuned\n",
    "- Make a function for training \n",
    "    - The function takes the search space or config as a parameter\n",
    "    - The training part is exactly the same as normal training\n",
    "    - Before training, define the model using the config parameters (shown below)\n",
    "    - Do not start the training automatically from epoch 0. Check the checkpoint and determine if the starting epoch is 0 or something else (shown below)\n",
    "- Define a function for testing \n",
    "    - Not neccesary but makes it easier \n",
    "    - Takes the model as a parameter\n",
    "- Define the search space as needed\n",
    "- Define the tuner with the required parameters (shown below)\n",
    "- Fit the tuner to get the results\n",
    "- Obtain the best results and create a model using these results\n",
    "- Train the best model and analyze its performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "# Modify the class to include the chosen parameters to be tuned\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, l1=10):\n",
    "        super(Model.self).__init__()\n",
    "\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Linear(3*32*32, l1, bias=True),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(l1, 3)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x = torch.flatten(x,1)\n",
    "        x = self.network(x)\n",
    "        return x\n",
    "    \n",
    "# Make a function for training\n",
    "def train_model(config):\n",
    "    model = Model(config[\"l1\"])\n",
    "    model = model.to(device)\n",
    "    criterion = nn.CrossEntropy()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=config['lr'])\n",
    "    checkpoint = train.get_checkpoint()\n",
    "    if checkpoint:\n",
    "        checkpoint_state = checkpoint.to_dict()\n",
    "        start_epoch = checkpoint_state[\"epoch\"]\n",
    "        model.load_state_dict(checkpoint_state[\"model_state_dict\"])\n",
    "        optimizer.load_state_dict(checkpoint_state[\"optimizer_state_dict\"])\n",
    "    else:\n",
    "        start_epoch = 0\n",
    "\n",
    "    for epoch in range(start_epoch,10):\n",
    "        running_loss = 0.0\n",
    "        for (inputs, labels) in enumerate(train_dataloader):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "       \n",
    "        val_loss = 0.0\n",
    "        val_steps = 0\n",
    "        total = 0\n",
    "        correct = 0\n",
    "        for i, data in enumerate(val_dataloader, 0):\n",
    "                    with torch.no_grad():\n",
    "                        inputs, labels = data\n",
    "                        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "                        outputs = model(inputs)\n",
    "                        _, predicted = torch.max(outputs.data, 1)\n",
    "                        total += labels.size(0)\n",
    "                        correct += (predicted == labels).sum().item()\n",
    "\n",
    "                        loss = criterion(outputs, labels)\n",
    "                        val_loss += loss.cpu().numpy()\n",
    "                        val_steps += 1\n",
    "\n",
    "        with tempfile.TemporaryDirectory() as temp_checkpoint_dir:\n",
    "            checkpoint = None\n",
    "            if (i + 1) % 5 == 0:\n",
    "                torch.save(\n",
    "                    model.state_dict(),\n",
    "                    os.path.join(temp_checkpoint_dir, \"model.pth\")\n",
    "                )\n",
    "                checkpoint = Checkpoint.from_directory(temp_checkpoint_dir)\n",
    "\n",
    "            train.report({\"accuracy\": (100 * correct / total)}, checkpoint=checkpoint)\n",
    "\n",
    "# Make a function for testing\n",
    "def test_model(model):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in test_loader:\n",
    "            images, labels = data\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    precision = precision_score(labels, predicted, average='macro')\n",
    "    recall = recall_score(labels, predicted, average='macro')\n",
    "    f1 = f1_score(labels, predicted, average='macro')\n",
    "\n",
    "    return (100 * correct / total), precision, recall, f1\n",
    "\n",
    "# Define the search space\n",
    "config = {\n",
    "    \"l1\": tune.choice([2 ** i for i in range(6)]),\n",
    "    \"lr\": tune.loguniform(1e-4, 1e-1)\n",
    "}\n",
    "\n",
    "# Define the tuner\n",
    "tuner = tune.Tuner(\n",
    "  train_model,\n",
    "  tune_config=tune.TuneConfig(\n",
    "      num_samples=10,\n",
    "      scheduler=ASHAScheduler(metric=\"accuracy\", mode=\"max\"),\n",
    "  ),\n",
    "  param_space=config,\n",
    ")\n",
    "\n",
    "# Fit the tuner\n",
    "result = tuner.fit()\n",
    "\n",
    "# Use the best results to get the best model\n",
    "best_result = result.get_best_result(\"accuracy\", mode=\"max\")\n",
    "with best_result.checkpoint.as_directory() as checkpoint_dir:\n",
    "    state_dict = torch.load(os.path.join(checkpoint_dir, \"model.pth\"))\n",
    "\n",
    "model_tuned = Model(best_result.config['l1'])\n",
    "model_tuned = model_tuned.to(device)\n",
    "\n",
    "# Continue by training the model and checking its performance"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "99d21865-b920-4f93-b6c2-b2c77832f569",
   "metadata": {},
   "source": [
    "# **Optical Flow**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "260ea2f0-63ae-4c3c-91c0-cd342a982855",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## **Start up Code**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bba82325-3491-4ad6-993c-cc27c616dc1c",
   "metadata": {},
   "source": [
    "**Imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2e20faa5-720e-4f93-b320-2955de58d43f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e803bd9-97bc-4293-8a2a-57764e7a9850",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## **1. Theory**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad710efb-0851-4c5e-92ac-a3237ce07f74",
   "metadata": {},
   "source": [
    "I think it'll be more effective to learn about this topic through a video rather than reading about it. You might want to watch a few video on the topic:\n",
    "- *[Overview of Optical Flow](https://youtu.be/lnXFcmLB7sM?si=DP2z33qdBUr-ta25)*\n",
    "- *[Motion Field and Optical Flow](https://www.youtube.com/watch?v=fLzhaY90ym4&list=PL2zRqk16wsdoYzrWStffqBAoUY8XdvatV&index=3)*\n",
    "- *[Optical Flow Constraint Equation](https://youtu.be/IjPLZ3hjU1A?si=ahbaHejQrEFngV7s)*\n",
    "- *[Lucas-Kanade Method](https://youtu.be/6wMoHgpVUn8?si=7lqpVqi5ElOj-Chm)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa955d38-fe5e-4755-9fa8-b31e89f0491c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## **2. Implementation**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68be7a97-d7fb-490c-978e-1c370594250d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### **2.1 Example 1: Single Object Tracking w/ Lucas-Kanade**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "354caba4-95cd-415b-93e9-5e5bc50a805b",
   "metadata": {},
   "source": [
    "In this example, we'll demonstrate how to track a single object moving in a video.\n",
    "\n",
    "Before proceeding, let's discuss what exactly we're doing because it can (will) get a bit messy. Our broader goal is to implement optical flow tracking on a video. Optical flow in computer vision enables us to track the motion of objects in a sequence of images (or frames) over time. It calculates the displacement of certain points (`prevPts` and `nextPts`) between consecutive frames (`prevImg` and `nextImg`), allowing us to estimate the movement patterns within the video."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2879c13-4621-47f2-aba3-c3a9630e2976",
   "metadata": {},
   "source": [
    "We'll begin by initializing a video capture object (`cap`) to read frames from a video file.\n",
    "\n",
    "The function `cv2.VideoCapture()` enables users to read in a video or specify the camera source.\n",
    "- To read a video, simply provide the file path.\n",
    "- To read from a camera source, pass the index of the input source. To open the default camera (webcam), pass 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b8e3f76d-7f17-4a1d-967c-6f2d0701f44f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a VideoCapture object to read frames from the specified video file\n",
    "cap = cv2.VideoCapture('./data/videos/carchase.mp4')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0291353-d337-48c7-a914-7ec59b14e2bf",
   "metadata": {},
   "source": [
    "To proceed, we'll make use of the Lucas-Kanade algorithm by utilizing the calcOpticalFlowPyrLK function provided by OpenCV. This function allows us to estimate the motion of keypoints between two consecutive frames in a video sequence.\n",
    "\n",
    "`nextPts, status, err = cv2.calcOpticalFlowPyrLK(prevImg, nextImg, prevPts, nextPts, winSize = , maxLevel = )`\n",
    "- **prevImg**: The previous frame in the video sequence.\n",
    "- **nextImg**: The next frame in the video sequence.\n",
    "- **prevPts**: The vector of 2D points for which the flow needs to be found\n",
    "- **winSize**: Size of the averaging window for optical flow. It determines the size of the neighborhood considered for calculating optical flow.\n",
    "- **maxLevel**: Specifies the 0-based maximal pyramid level number. This parameter controls the maximum level of pyramid to use for the algorithm\n",
    "\n",
    "The return values are as follows:\n",
    "- **nextPts**: Output vector of 2D points containing the calculated new positions of the input points in the next image.\n",
    "- **status**: Output status vector. If '1', then 'nextPts[i]' is found. Otherwise, 'nextPts[i]' is not found.\n",
    "- **err**: Output vector that will contain the difference between patches around the orignal and moved points. This is an optional output and can be omitted if not needed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2fcd747-7250-49ec-ba06-c36cc66a15cf",
   "metadata": {},
   "source": [
    "We'll go ahead and initialize `prevPts`. This array is used to track the movement of points in subsequent frames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2c6f9ae5-e344-4e3d-93ff-cfb23bca6be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "prevPts = np.array((200, 106)).reshape(-1, 1, 2).astype(np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ff6b063-5041-4952-8d29-95e32cf0161b",
   "metadata": {},
   "source": [
    "We'll now set the window size for the Lucas-kanade optical flow algorithm. Again, this determines the size of the window for tracking points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0bbb06d0-f5a6-486d-b97c-e2769a653b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "winSize = (21, 21)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b262a44a-e990-4a88-9766-28b2c39932ba",
   "metadata": {},
   "source": [
    "Moving forward, we can extract individual frames from a video by using the `read()` method on the `VideoCapture` object.\n",
    "\n",
    "`(ret, frame) = cv2.videoCapture.read()`\n",
    "- **ret**: A boolean value indicating whether a frame was successfully read.\n",
    "- **frame**: If 'ret' is 'True', 'frame' contains the next frame read from the video source as a NumPy array in BGR format.\n",
    "\n",
    "After extracting the frame, we'll proceed to convert it to grayscale. Grayscale images are commonly used for optical flow calculation as they simplify processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "066da484-31ef-4167-8228-eff466c59689",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read a frame from the video capture object\n",
    "ret, frame = cap.read()\n",
    "\n",
    "# Convert the frame to grayscale using the cvtColor function\n",
    "prevImg = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e7dbb00-0238-413a-9263-70396312586c",
   "metadata": {},
   "source": [
    "We can now combine our knowledge to create a loop for processing the frames in the video as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3c5836ec-02e4-404e-81f7-03c920430e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop until the video capture object is open\n",
    "while cap.isOpened():\n",
    "    # Read a frame from the video capture object\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    # Convert the frame to grayscale\n",
    "    nextImg = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Calculate optical flow using Lucas-Kanade method\n",
    "    nextPts, status, err = cv2.calcOpticalFlowPyrLK(prevImg, nextImg, prevPts, None, winSize=winSize, maxLevel=3)\n",
    "\n",
    "    # Filter out points with a valid status\n",
    "    prevPts = prevPts[status == 1]\n",
    "    nextPts = nextPts[status == 1]\n",
    "\n",
    "    # Draw optical flow vectors on the frame\n",
    "    for i, (old_point, new_point) in enumerate(zip(prevPts, nextPts)):\n",
    "        frame = cv2.rectangle(\n",
    "            frame, \n",
    "            new_point.astype(int) - winSize[0]//2,  # Draw rectangle around new point\n",
    "            new_point.astype(int) + winSize[0]//2,  # Draw rectangle around old point\n",
    "            [0, 0, 255],  # Color of the rectangle (red)\n",
    "            2)  # Thickness of the rectangle\n",
    "\n",
    "    # Display the frame with optical flow vectors\n",
    "    cv2.imshow('Video', frame)\n",
    "\n",
    "    # Check if the 'q' key is pressed to quit\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "\n",
    "    # Update previous image and points for the next iteration\n",
    "    prevImg = nextImg\n",
    "    prevPts = nextPts.reshape(-1, 1, 2)\n",
    "\n",
    "# Release the video capture object and close all OpenCV windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bcab883-5b8b-44e4-8113-403588f12b3c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### **2.2 Example 2: Multiple Object Tracking w/ Lucas-Kanade**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1b4298fd-fa64-4af7-973c-dcf7aac74ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the video file for reading\n",
    "cap = cv2.VideoCapture('./data/videos/people.mp4')\n",
    "\n",
    "# Number of points to track\n",
    "n = 100\n",
    "\n",
    "# Size of the window for Lucas-Kanade\n",
    "winSize = (15, 15)\n",
    "\n",
    "# Read the first frame from the video\n",
    "ret, frame = cap.read()\n",
    "\n",
    "# Convert the first frame to grayscale\n",
    "prevImg = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Detect good features to track using Shi-Tomasi corner detection\n",
    "points = cv2.goodFeaturesToTrack(prevImg, maxCorners=n, qualityLevel=0.1, minDistance=7)\n",
    "\n",
    "# Generate random colors for the points\n",
    "color = np.random.randint(0, 255, (n, 3))\n",
    "\n",
    "# Store the initial set of points\n",
    "prevPts = points\n",
    "\n",
    "# Loop through the frames of the video\n",
    "while cap.isOpened():\n",
    "    # Read a frame from the video\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    # Check if frame is successfully read\n",
    "    if not ret:\n",
    "        print(\"Can't receive frame (stream end?). Exiting ...\")\n",
    "        break\n",
    "    \n",
    "    # Convert the current frame to grayscale\n",
    "    nextImg = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Calculate optical flow using Lucas-Kanade method\n",
    "    nextPts, status, err = cv2.calcOpticalFlowPyrLK(prevImg, nextImg, prevPts, None, winSize=winSize, maxLevel=3)\n",
    "    \n",
    "    # Select only the points with valid status\n",
    "    prevPts = prevPts[status == 1]\n",
    "    nextPts = nextPts[status == 1]\n",
    "    points = points[status == 1]\n",
    "    color = color.reshape(-1, 1, 3)[status == 1]\n",
    "    \n",
    "    # Display a line between the old and new positions of the points\n",
    "    for i, (old_point, new_point) in enumerate(zip(points, nextPts)):\n",
    "        frame = cv2.line(\n",
    "            frame, \n",
    "            tuple(old_point.astype(int)), \n",
    "            tuple(new_point.astype(int)), \n",
    "            color[i].tolist(), \n",
    "            2)\n",
    "        \n",
    "        frame = cv2.rectangle(\n",
    "            frame, \n",
    "            tuple(new_point.astype(int) - np.array(winSize)//2), \n",
    "            tuple(new_point.astype(int) + np.array(winSize)//2), \n",
    "            color[i].tolist(), \n",
    "            2)\n",
    "    \n",
    "    # Display the frame with optical flow\n",
    "    cv2.imshow('frame', frame)\n",
    "    \n",
    "    # Break the loop if 'q' key is pressed\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "    \n",
    "    # Update the previous frame and points for the next iteration\n",
    "    prevImg = nextImg\n",
    "    prevPts = nextPts.reshape(-1, 1, 2)\n",
    "    points = points.reshape(-1, 1, 2)\n",
    "\n",
    "# Release the video capture object and close all OpenCV windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0447b6d0-971f-405c-9060-bf1248e8adfe",
   "metadata": {},
   "source": [
    "The code filters out points that were not succesfully tracked and visualizes the movement of the tracked points. It draws lines connecting the old and new positions of the tracked points and draws rectangles around the new positions to indicate their movement."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
